{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a href=\"http://www.pinsdaddy.com/pittsburgh-pa-area-map_LaF3VctaPpxf6lh1NCy0vAAlxhUWkl1212ESeozWFD8/\"><img src=\"pittsburghmetrowallmap.jpg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Autonomus Vehicle Deployment dataset has 938 survey responces with 10 variables each.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Python 2.7\n",
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the Autonomus Vehicle Deployment in Pittsburgh dataset\n",
    "data = pd.read_csv('data_prep_AV.csv')\n",
    "\n",
    "zipcodes = data['ZipCode']\n",
    "pedestrian = data['Pedestrian']\n",
    "familiarity = data['Familiarity'] \n",
    "approval = data['Approval'] \n",
    "neutral = data['Approval']\n",
    "disapproval = data['Approval']\n",
    "    \n",
    "# Success\n",
    "print \"\\nAutonomus Vehicle Deployment dataset has {} survey responces with {} variables each.\\n\".format(*data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of Autonomus Vehicle Deployment in Pittsburgh Dataset with 938 responces:\n",
      "\n",
      "684, which is %72 of participants are familiar with AV\n",
      "\n",
      "680, which is %72 of participants approve deployment of AV\n",
      "119, which is %12 of participants neutral to deployment of AV\n",
      "139, which is %14 of participants disapprove deployment of AV\n",
      "\n",
      "535, which is %57 of participants familiar with AV and approve deployment\n",
      "82, which is %8 of participants familiar with AV and disapprove deployment\n",
      "67, which is %7 of participants familiar with AV and neutral to deployment\n",
      "\n",
      "145, which is %15 of participants not familiar with AV and approve deployment\n",
      "57, which is %6 of participants not familiar with AV and disapprove deployment\n",
      "52, which is %5 of participants not familiar with AV and neutral to deployment\n"
     ]
    }
   ],
   "source": [
    "# How many people familiar with AV\n",
    "familiar_AV = np.sum(familiarity)\n",
    "\n",
    "# How many people approve deployment of AV\n",
    "approval_AV = np.sum(num for num in approval if num == 1)\n",
    "\n",
    "# How many people neutral to deployment of AV\n",
    "neutral_AV = np.sum(num/2 for num in neutral if num == 2)\n",
    "\n",
    "# How many people disapprove deployment of AV\n",
    "disapproval_AV = 0\n",
    "for i in range(938):\n",
    "    if approval[i] == 0:\n",
    "        disapproval_AV += 1\n",
    "\n",
    "# How many people familiar with AV and disapprove deployment\n",
    "fam_disapp_AV = 0\n",
    "for i in range(938):\n",
    "    if approval[i] == 0:\n",
    "        if familiarity[i] == 1:\n",
    "            fam_disapp_AV += 1\n",
    "\n",
    "# How many people familiar with AV and neutral to deployment\n",
    "fam_neut_AV = 0\n",
    "for i in range(938):\n",
    "    if approval[i] == 2:\n",
    "        if familiarity[i] == 1:\n",
    "            fam_neut_AV += 1\n",
    "\n",
    "# How many people familiar with AV and approve deployment\n",
    "fam_app_AV = 0\n",
    "for i in range(938):\n",
    "    if approval[i] == familiarity[i] == 1:\n",
    "        fam_app_AV += 1\n",
    "        \n",
    "# How many people not familiar with AV and approve deployment\n",
    "notfam_app_AV = 0\n",
    "for i in range(938):\n",
    "    if approval[i] == 1:\n",
    "        if familiarity[i] == 0:\n",
    "            notfam_app_AV += 1\n",
    "\n",
    "# How many people notfamiliar with AV and neutral to deployment\n",
    "notfam_neut_AV = 0\n",
    "for i in range(938):\n",
    "    if approval[i] == 2:\n",
    "        if familiarity[i] == 0:\n",
    "            notfam_neut_AV += 1\n",
    "\n",
    "# How many people not familiar with AV and disapprove deployment\n",
    "notfam_disapp_AV = 0\n",
    "for i in range(938):\n",
    "    if approval[i] == familiarity[i] == 0:\n",
    "        notfam_disapp_AV += 1\n",
    "        \n",
    "print(\"Statistics of Autonomus Vehicle Deployment in Pittsburgh Dataset with 938 responces:\\n\")\n",
    "print \"{}, which is %{} of participants are familiar with AV\".format(familiar_AV, 100*familiar_AV/938)\n",
    "\n",
    "print \"\\n{}, which is %{} of participants approve deployment of AV\".format(approval_AV, 100*approval_AV/938)\n",
    "print \"{}, which is %{} of participants neutral to deployment of AV\".format(neutral_AV, 100*neutral_AV/938)\n",
    "print \"{}, which is %{} of participants disapprove deployment of AV\".format(disapproval_AV, 100*disapproval_AV/938)\n",
    "\n",
    "print \"\\n{}, which is %{} of participants familiar with AV and approve deployment\".format(fam_app_AV, 100*fam_app_AV/938)\n",
    "print \"{}, which is %{} of participants familiar with AV and disapprove deployment\".format(fam_disapp_AV, 100*fam_disapp_AV/938)\n",
    "print \"{}, which is %{} of participants familiar with AV and neutral to deployment\".format(fam_neut_AV, 100*fam_neut_AV/938)\n",
    "\n",
    "print \"\\n{}, which is %{} of participants not familiar with AV and approve deployment\".format(notfam_app_AV, 100*notfam_app_AV/938)\n",
    "print \"{}, which is %{} of participants not familiar with AV and disapprove deployment\".format(notfam_disapp_AV, 100*notfam_disapp_AV/938)\n",
    "print \"{}, which is %{} of participants not familiar with AV and neutral to deployment\".format(notfam_neut_AV, 100*notfam_neut_AV/938)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Zip  : # Participants\n",
      "----------------------\n",
      "15232 : 43\n",
      "15233 : 6\n",
      "15234 : 2\n",
      "15235 : 4\n",
      "15236 : 3\n",
      "15237 : 20\n",
      "15238 : 12\n",
      "15239 : 2\n",
      "15241 : 8\n",
      "15243 : 6\n",
      "15201 : 69\n",
      "15202 : 16\n",
      "15203 : 36\n",
      "15204 : 6\n",
      "15205 : 8\n",
      "15206 : 102\n",
      "15207 : 18\n",
      "15208 : 28\n",
      "15209 : 13\n",
      "15210 : 7\n",
      "15211 : 20\n",
      "15212 : 70\n",
      "15213 : 33\n",
      "15214 : 6\n",
      "15215 : 13\n",
      "15216 : 18\n",
      "15217 : 122\n",
      "15218 : 40\n",
      "15219 : 21\n",
      "15220 : 8\n",
      "15221 : 43\n",
      "15222 : 37\n",
      "15223 : 3\n",
      "15224 : 62\n",
      "15226 : 5\n",
      "15227 : 4\n",
      "15228 : 18\n",
      "15229 : 6\n",
      "\n",
      "\n",
      "0 : 254\n",
      "1 : 684\n",
      "\n",
      "\n",
      "0 : 139\n",
      "1 : 680\n",
      "2 : 119\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# How many people from which zipcode participated\n",
    "zip_participants = collections.Counter(zipcodes)\n",
    "zip_familiarity = collections.Counter(familiarity)\n",
    "zip_approval = collections.Counter(approval)\n",
    "\n",
    "print(\" Zip  : # Participants\")\n",
    "print(\"----------------------\")\n",
    "for code in zip_participants:\n",
    "    print ('%d : %d' % (code, zip_participants[code]))\n",
    "\n",
    "print(\"\\n\")\n",
    "for familiar in zip_familiarity:\n",
    "    print ('%d : %d' % (familiar, zip_familiarity[familiar]))\n",
    "    \n",
    "print(\"\\n\")\n",
    "for approv in zip_approval:\n",
    "    print ('%d : %d' % (approv, zip_approval[approv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pedestrian</th>\n",
       "      <th>Bicycle</th>\n",
       "      <th>Familiarity</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Population</th>\n",
       "      <th>AvgIncomeHouse</th>\n",
       "      <th>ZHVI</th>\n",
       "      <th>AllBeneficiaries</th>\n",
       "      <th>PerBeneficiaries</th>\n",
       "      <th>Approval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15201</td>\n",
       "      <td>14326</td>\n",
       "      <td>27031</td>\n",
       "      <td>129000</td>\n",
       "      <td>2920</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15201</td>\n",
       "      <td>14326</td>\n",
       "      <td>27031</td>\n",
       "      <td>129000</td>\n",
       "      <td>2920</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15201</td>\n",
       "      <td>14326</td>\n",
       "      <td>27031</td>\n",
       "      <td>129000</td>\n",
       "      <td>2920</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15201</td>\n",
       "      <td>14326</td>\n",
       "      <td>27031</td>\n",
       "      <td>129000</td>\n",
       "      <td>2920</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15201</td>\n",
       "      <td>14326</td>\n",
       "      <td>27031</td>\n",
       "      <td>129000</td>\n",
       "      <td>2920</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pedestrian  Bicycle  Familiarity  ZipCode  Population  AvgIncomeHouse  \\\n",
       "0           1        1            1    15201       14326           27031   \n",
       "1           1        0            0    15201       14326           27031   \n",
       "2           1        0            0    15201       14326           27031   \n",
       "3           1        2            1    15201       14326           27031   \n",
       "4           0        1            1    15201       14326           27031   \n",
       "\n",
       "     ZHVI  AllBeneficiaries  PerBeneficiaries  Approval  \n",
       "0  129000              2920               0.2         0  \n",
       "1  129000              2920               0.2         0  \n",
       "2  129000              2920               0.2         0  \n",
       "3  129000              2920               0.2         0  \n",
       "4  129000              2920               0.2         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Print the first few entries of the Survey Data\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['Pedestrian', 'Bicycle', 'Familiarity', 'ZipCode', 'Population', 'AvgIncomeHouse', 'ZHVI', 'AllBeneficiaries', 'PerBeneficiaries']\n",
      "\n",
      "Target column: Approval\n",
      "\n",
      "Feature values:\n",
      "   Pedestrian  Bicycle  Familiarity  ZipCode  Population  AvgIncomeHouse  \\\n",
      "0           1        1            1    15201       14326           27031   \n",
      "1           1        0            0    15201       14326           27031   \n",
      "2           1        0            0    15201       14326           27031   \n",
      "3           1        2            1    15201       14326           27031   \n",
      "4           0        1            1    15201       14326           27031   \n",
      "\n",
      "     ZHVI  AllBeneficiaries  PerBeneficiaries  \n",
      "0  129000              2920               0.2  \n",
      "1  129000              2920               0.2  \n",
      "2  129000              2920               0.2  \n",
      "3  129000              2920               0.2  \n",
      "4  129000              2920               0.2  \n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(data.columns[:-1])\n",
    "\n",
    "# Extract target column 'passed'\n",
    "target_col = data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print \"Feature columns:\\n{}\".format(feature_cols)\n",
    "print \"\\nTarget column: {}\".format(target_col)\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = data[feature_cols]\n",
    "y_all = data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 700 samples.\n",
      "Testing set has 238 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import any additional functionality you may need here\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Set the number of training points\n",
    "num_train = 700\n",
    "\n",
    "# Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, train_size=num_train, random_state=42)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (9 total features):\n",
      "['Pedestrian', 'Bicycle', 'Familiarity', 'ZipCode', 'Population', 'AvgIncomeHouse', 'ZHVI', 'AllBeneficiaries', 'PerBeneficiaries']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['1', '2'], [1, 1])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 700 samples.\n",
      "Testing set has 238 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import any additional functionality you may need here\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Set the number of training points\n",
    "num_train = 700\n",
    "\n",
    "# Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, train_size=num_train, random_state=42)\n",
    "\n",
    "# Show the results of the split\n",
    "print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    \n",
    "    # Print the results\n",
    "    print \"Trained model in {:.4f} seconds\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print \"Made predictions in {:.4f} seconds.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='1', average='weighted')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print \"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print \"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model 1 200: DecisionTreeClassifier\n",
      "Training a DecisionTreeClassifier using a training set size of 200. . .\n",
      "Trained model in 0.0018 seconds\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for training set: 0.8832.\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for test set: 0.6006.\n",
      "\n",
      " Model 1 500: DecisionTreeClassifier\n",
      "Training a DecisionTreeClassifier using a training set size of 500. . .\n",
      "Trained model in 0.0016 seconds\n",
      "Made predictions in 0.0007 seconds.\n",
      "F1 score for training set: 0.7984.\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for test set: 0.6013.\n",
      "\n",
      " Model 1 700: DecisionTreeClassifier\n",
      "Training a DecisionTreeClassifier using a training set size of 700. . .\n",
      "Trained model in 0.0020 seconds\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for training set: 0.7637.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.6005.\n",
      "\n",
      " Model 2 200: GaussianNB\n",
      "Training a GaussianNB using a training set size of 200. . .\n",
      "Trained model in 0.0008 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.6294.\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for test set: 0.6119.\n",
      "\n",
      " Model 2 500: GaussianNB\n",
      "Training a GaussianNB using a training set size of 500. . .\n",
      "Trained model in 0.0013 seconds\n",
      "Made predictions in 0.0003 seconds.\n",
      "F1 score for training set: 0.6107.\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for test set: 0.6119.\n",
      "\n",
      " Model 2 700: GaussianNB\n",
      "Training a GaussianNB using a training set size of 700. . .\n",
      "Trained model in 0.0009 seconds\n",
      "Made predictions in 0.0005 seconds.\n",
      "F1 score for training set: 0.6085.\n",
      "Made predictions in 0.0004 seconds.\n",
      "F1 score for test set: 0.6119.\n",
      "\n",
      " Model 3 200: SVC\n",
      "Training a SVC using a training set size of 200. . .\n",
      "Trained model in 0.0016 seconds\n",
      "Made predictions in 0.0006 seconds.\n",
      "F1 score for training set: 0.6632.\n",
      "Made predictions in 0.0008 seconds.\n",
      "F1 score for test set: 0.6099.\n",
      "\n",
      " Model 3 500: SVC\n",
      "Training a SVC using a training set size of 500. . .\n",
      "Trained model in 0.0090 seconds\n",
      "Made predictions in 0.0030 seconds.\n",
      "F1 score for training set: 0.6154.\n",
      "Made predictions in 0.0016 seconds.\n",
      "F1 score for test set: 0.6119.\n",
      "\n",
      " Model 3 700: SVC\n",
      "Training a SVC using a training set size of 700. . .\n",
      "Trained model in 0.0181 seconds\n",
      "Made predictions in 0.0057 seconds.\n",
      "F1 score for training set: 0.6118.\n",
      "Made predictions in 0.0033 seconds.\n",
      "F1 score for test set: 0.6119.\n"
     ]
    }
   ],
   "source": [
    "# Import the three supervised learning models from sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# from sklearn import model_B\n",
    "# from skearln import model_C\n",
    "\n",
    "# Initialize the three models\n",
    "clf_A = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf_B = GaussianNB()\n",
    "clf_C = svm.SVC(random_state=42)\n",
    "\n",
    "# Set up the training set sizes\n",
    "X_train_200 = 200\n",
    "y_train_200 = 200\n",
    "\n",
    "X_train_500 = 500\n",
    "y_train_500 = 500\n",
    "\n",
    "X_train_700 = 700\n",
    "y_train_700 = 700\n",
    "\n",
    "# Execute the 'train_predict' function for each classifier and each training set size\n",
    "print \"\\n Model 1 200: DecisionTreeClassifier\"\n",
    "train_predict(clf_A, X_train[:X_train_200], y_train[:y_train_200], X_test, y_test)\n",
    "print \"\\n Model 1 500: DecisionTreeClassifier\"\n",
    "train_predict(clf_A, X_train[:X_train_500], y_train[:y_train_500], X_test, y_test)\n",
    "print \"\\n Model 1 700: DecisionTreeClassifier\"\n",
    "train_predict(clf_A, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print \"\\n Model 2 200: GaussianNB\"\n",
    "train_predict(clf_B, X_train[:X_train_200], y_train[:y_train_200], X_test, y_test)\n",
    "print \"\\n Model 2 500: GaussianNB\"\n",
    "train_predict(clf_B, X_train[:X_train_500], y_train[:y_train_500], X_test, y_test)\n",
    "print \"\\n Model 2 700: GaussianNB\"\n",
    "train_predict(clf_B, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print \"\\n Model 3 200: SVC\"\n",
    "train_predict(clf_C, X_train[:X_train_200], y_train[:y_train_200], X_test, y_test)\n",
    "print \"\\n Model 3 500: SVC\"\n",
    "train_predict(clf_C, X_train[:X_train_500], y_train[:y_train_500], X_test, y_test)\n",
    "print \"\\n Model 3 700: SVC\"\n",
    "train_predict(clf_C, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made predictions in 0.0062 seconds.\n",
      "Tuned model has a training F1 score of 0.6495.\n",
      "Made predictions in 0.0026 seconds.\n",
      "Tuned model has a testing F1 score of 0.6009.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "parameters = [{'C': [1, 10, 100, 200, 300, 400, 500, 600, 700, 1000],\n",
    "   'gamma': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "   'kernel': ['rbf'], 'tol':[1e-3, 1e-4, 1e-5, 1e-6]\n",
    "  }]\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = svm.SVC()\n",
    "\n",
    "# Make an f1 scoring function using 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label='1', average='macro')\n",
    "\n",
    "# Perform grid search on the classifier using the f1_scorer as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring = f1_scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "slf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "print \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(slf, X_train, y_train))\n",
    "print \"Tuned model has a testing F1 score of {:.4f}.\".format(predict_labels(slf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
